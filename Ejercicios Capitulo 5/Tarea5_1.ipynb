{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOF31JOoL9/GcMxfiSf+Rnm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Capitulo 5 Ejercicio 1\n",
        "\n",
        "Se busca entrenar una red neuronal para predecir el valor de cualquier acción para\n",
        "mañana. Busque valores de la acción y de otras tres variables que considere influyen\n",
        "en el valor de esa acción. O el problema de predecir el valor del dólar, que se planteo\n",
        "en el capítulo anterior.\n",
        "\n",
        "Utilizamos lo planteado en el capitulo anterior teniendo en cuenta las acciones de bancolombia y ecopetrol"
      ],
      "metadata": {
        "id": "rY2bNJFdf2z3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos un archivo csv con acciones ficticias para poder usar en nuestro entrenamiento de la red neuronal"
      ],
      "metadata": {
        "id": "uZGvxgNygSn7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xlQms-wfer-N"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Crear una lista de fechas ficticias\n",
        "fecha_inicial = datetime(2023, 9, 1)\n",
        "fechas = [fecha_inicial + timedelta(days=i) for i in range(10)]\n",
        "\n",
        "# Crear listas con valores ficticios para cada columna\n",
        "valor_accion_ecopetrol = [random.uniform(12, 13) for _ in range(10)]\n",
        "valor_accion_bancocolombia = [random.uniform(28, 31) for _ in range(10)]\n",
        "precio_petroleo = [random.uniform(70, 75) for _ in range(10)]\n",
        "trm = [random.uniform(3500, 3650) for _ in range(10)]\n",
        "accion_siguiente_dia = [random.uniform(12, 13) for _ in range(10)]\n",
        "\n",
        "# Crear un DataFrame de pandas con los datos ficticios\n",
        "data = pd.DataFrame({\n",
        "    'Fecha': fechas,\n",
        "    'Valor_Accion_Ecopetrol': valor_accion_ecopetrol,\n",
        "    'Valor_Accion_BancoColombia': valor_accion_bancocolombia,\n",
        "    'Precio_Petroleo': precio_petroleo,\n",
        "    'TRM': trm,\n",
        "    'Accion_Siguiente_Dia': accion_siguiente_dia\n",
        "})\n",
        "\n",
        "# Guardar el DataFrame en un archivo CSV\n",
        "data.to_csv('datos_acciones.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenamos y evaluamos una red neuronal en Python utilizando TensorFlow/Keras para predecir el precio de una acción en función de variables como el valor de las acciones de Ecopetrol y Bancolombia, así como el precio del petróleo"
      ],
      "metadata": {
        "id": "XPmoq4O6gdFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Cargar tus datos en un DataFrame de pandas\n",
        "# Asumiendo que tienes un archivo CSV con tus datos\n",
        "data = pd.read_csv('datos_acciones.csv')  # Reemplaza 'datos_acciones.csv' con el nombre de tu archivo\n",
        "\n",
        "# Seleccionar las columnas relevantes\n",
        "X = data[['Valor_Accion_Ecopetrol', 'Valor_Accion_BancoColombia', 'Precio_Petroleo']]\n",
        "y = data['Accion_Siguiente_Dia']\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalizar los datos\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Crear el modelo de red neuronal\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(1)  # Una sola neurona de salida para la predicción del precio\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluar el modelo\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Error cuadrático medio en el conjunto de prueba: {loss}')\n",
        "\n",
        "# Realizar predicciones para el día siguiente\n",
        "nuevos_datos = np.array([[valor_accion_ecopetrol[-1], valor_accion_bancocolombia[-1], precio_petroleo[-1]]])\n",
        "nuevos_datos = scaler.transform(nuevos_datos)\n",
        "prediccion = model.predict(nuevos_datos)\n",
        "print(f'Predicción del precio de la acción para mañana: {prediccion[0][0]}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28rRkt9beyUi",
        "outputId": "ea82827a-18ee-47ac-f8ba-adf16cac5567"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1/1 [==============================] - 1s 768ms/step - loss: 161.6406 - val_loss: 153.4446\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 160.4437 - val_loss: 152.6378\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 159.2547 - val_loss: 151.8576\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 158.0778 - val_loss: 151.1026\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 156.9284 - val_loss: 150.3891\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 155.7928 - val_loss: 149.7181\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 154.6974 - val_loss: 149.0447\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 153.6120 - val_loss: 148.3589\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 152.5422 - val_loss: 147.6725\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 151.4691 - val_loss: 146.9774\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 150.4057 - val_loss: 146.2688\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 149.3458 - val_loss: 145.5615\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 148.2734 - val_loss: 144.8599\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 147.2207 - val_loss: 144.1160\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 146.1777 - val_loss: 143.3683\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 145.1338 - val_loss: 142.6314\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 144.1035 - val_loss: 141.9261\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 143.0705 - val_loss: 141.2210\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 142.0340 - val_loss: 140.5492\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 140.9932 - val_loss: 139.8993\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 139.9465 - val_loss: 139.2516\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 138.8918 - val_loss: 138.6126\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 137.8232 - val_loss: 137.9598\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 136.7458 - val_loss: 137.2828\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 135.6557 - val_loss: 136.5992\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 134.5482 - val_loss: 135.9046\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 133.4040 - val_loss: 135.2014\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 132.2503 - val_loss: 134.4834\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 131.1009 - val_loss: 133.7075\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 129.9356 - val_loss: 132.9159\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 128.7547 - val_loss: 132.0832\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 127.5398 - val_loss: 131.2358\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 126.2998 - val_loss: 130.3726\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 125.0402 - val_loss: 129.4949\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 123.7624 - val_loss: 128.6033\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 122.4666 - val_loss: 127.6966\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 121.1531 - val_loss: 126.7056\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 119.8245 - val_loss: 125.7025\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 118.4791 - val_loss: 124.6922\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 117.1195 - val_loss: 123.6691\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 115.7484 - val_loss: 122.6333\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 114.3653 - val_loss: 121.5788\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 112.9654 - val_loss: 120.4947\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 111.5459 - val_loss: 119.3913\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 110.0947 - val_loss: 118.2671\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 108.6164 - val_loss: 117.1229\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 107.1161 - val_loss: 115.9596\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 105.5965 - val_loss: 114.7773\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 104.0586 - val_loss: 113.5766\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 102.4932 - val_loss: 112.3569\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 112.3569\n",
            "Error cuadrático medio en el conjunto de prueba: 112.35685729980469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 150ms/step\n",
            "Predicción del precio de la acción para mañana: 2.2226150035858154\n"
          ]
        }
      ]
    }
  ]
}